{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple, Callable\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import regularizers\n",
        "from keras.applications import MobileNetV2\n",
        "from keras.engine.training import Model\n",
        "import functools\n",
        "import os\n",
        "import numpy as np\n",
        "import pickle\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from imutils import paths\n",
        "from tensorflow.keras import applications\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from keras.applications.mobilenet_v2 import preprocess_input\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2dXhh7uXwiJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.mobilenet_v2 import preprocess_input\n",
        "train_dr= \"/content/drive/MyDrive/hj3vvx5946-1/hj3vvx5946-1/Splited_dataset/train\"\n",
        "train_images= list(paths.list_images(\"/content/drive/MyDrive/hj3vvx5946-1/hj3vvx5946-1/Splited_dataset/train\"))\n",
        "num_classes=len(os.listdir(train_dr))\n",
        "def get_mobilenetv2_full_tune_model_alpha_1_4_concatenated_regularised(_num_classes) \\\n",
        "        -> Tuple[Model, Model, int, Callable]:\n",
        "    image_size = 224\n",
        "    channels_count = 3\n",
        "    initial_model: Model = MobileNetV2(weights='imagenet', alpha=1.4, include_top=False,\n",
        "                                       input_shape=(image_size, image_size, channels_count))\n",
        "    initial_model.trainable= True\n",
        "    for i,layer in enumerate(initial_model.layers):\n",
        "       layer.trainable=True\n",
        "\n",
        "    initial_model_output=initial_model.output\n",
        "    x=layers.GlobalAveragePooling2D()(initial_model_output)\n",
        "    regularizer = regularizers.l2(0.01)\n",
        "    x=layers.Dense(1024, activation='relu', kernel_regularizer=regularizer)(x)\n",
        "    predictions = layers.Dense(_num_classes, activation='softmax')(x)\n",
        "\n",
        "    model=Model(initial_model.input, predictions)\n",
        "    return model, initial_model, image_size, preprocess_input\n",
        "\n",
        "\n",
        "def get_callbacks_list(_early_stopping_patience, _reduce_lr_on_plateau_factor,_reduce_lr_on_plateau_patience):\n",
        "    return[\n",
        "        keras.callbacks.EarlyStopping(\n",
        "            monitor='val_acc',\n",
        "            patience=_early_stopping_patience\n",
        "        ),\n",
        "        keras.callbacks.ModelCheckpoint(\n",
        "            verbose=1,\n",
        "            filepath='best_model.h5',\n",
        "            monitor='val_loss',\n",
        "            save_best_only=True\n",
        "        ),\n",
        "        keras.callbacks.ReduceLROnPlateau(\n",
        "            verbose=1,\n",
        "            monitor='val_loss',\n",
        "            factor=_reduce_lr_on_plateau_factor,\n",
        "            patience=_reduce_lr_on_plateau_patience\n",
        "        )\n",
        "    ]\n"
      ],
      "metadata": {
        "id": "YGTzlVvDwl1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=32\n",
        "init_lr=0.01\n",
        "momentum=0.9\n",
        "epochs= 5\n",
        "optimizer=keras.optimizers.SGD(learning_rate=init_lr, momentum=momentum)\n",
        "_early_stopping_patience=10\n",
        "_reduce_lr_on_plateau_factor=0.2\n",
        "_reduce_lr_on_plateau_patience=3\n",
        "\n",
        "model_function= get_mobilenetv2_full_tune_model_alpha_1_4_concatenated_regularised\n",
        "result = model_function(num_classes)\n",
        "model, conv_base, image_size, preprocess_function = result[:4]\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Xz6s8glTNdS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top10_acc = functools.partial(keras.metrics.top_k_categorical_accuracy, k=10)\n",
        "top10_acc.__name__ = 'top10_acc'\n",
        "\n",
        "# Compile the model:\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy', top10_acc])\n"
      ],
      "metadata": {
        "id": "LoMWrgXWj0tR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data preprocessing\n",
        "image_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_function,\n",
        "    rotation_range=5,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.1,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "train_generator= image_datagen.flow_from_directory(\n",
        "    train_dr,\n",
        "    target_size=(image_size,image_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "train_images_count=len(train_generator.filenames)\n",
        "\n",
        "validation_generator = image_datagen.flow_from_directory(\n",
        "    train_dr,\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "validation_images_count = len(validation_generator.filenames)\n",
        "\n",
        "with open('classes_name.pickle','wb') as handle:\n",
        "  pickle.dump(validation_generator.class_indices,handle,protocol=pickle.HIGHEST_PROTOCOL)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uV1bxx4OKBpY",
        "outputId": "84374ab0-2f7e-4d64-aa96-bdcaea02341d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2806 images belonging to 48 classes.\n",
            "Found 290 images belonging to 48 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_steps = len(train_generator.filenames) // batch_size\n",
        "validation_steps = len(validation_generator.filenames) // batch_size\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_steps,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_steps,\n",
        "    callbacks=get_callbacks_list(_early_stopping_patience, _reduce_lr_on_plateau_factor, _reduce_lr_on_plateau_patience)\n",
        ")\n"
      ],
      "metadata": {
        "id": "Qbd-e8Ricc_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_score = model.evaluate_generator(validation_generator, steps=validation_steps)\n",
        "print('Validation loss: ', validation_score[0])\n",
        "print('Validation acc:  ', validation_score[1])\n",
        "print('Validation top 10 score:  ', validation_score[2])"
      ],
      "metadata": {
        "id": "2raXo566Idbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.utils as image\n",
        "from keras.models import load_model\n",
        "top10_acc = functools.partial(keras.metrics.top_k_categorical_accuracy, k=10)\n",
        "top10_acc.__name__ = 'top10_acc'\n",
        "\n",
        "model = load_model('best_model.h5',custom_objects={'top10_acc': top10_acc})\n",
        "\n",
        "with open('classes_name.pickle', 'rb') as handle:\n",
        "    classes_name = pickle.load(handle)"
      ],
      "metadata": {
        "id": "HrLonaajr8x1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_path='/content/drive/MyDrive/car_data/car_data/85.jpg'\n",
        "image_size=224\n",
        "img=image.load_img(img_path,target_size=(image_size,image_size))\n",
        "\n",
        "x=image.img_to_array(img)\n",
        "prediction=model.predict(x.reshape(1,image_size,image_size,3))\n",
        "\n",
        "prediction_index_5=prediction.reshape(-1).argsort()[-5:][::-1]\n",
        "print (np.c_[np.array(list((classes_name.keys())))[prediction_index_5],prediction.reshape(-1,)[prediction_index_5]*100])\n",
        "img"
      ],
      "metadata": {
        "id": "kwLbPMLJQ3uI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}